{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library Setup"
      ],
      "metadata": {
        "id": "Dv9EhX0WvBHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_sJ3Mzm74tF",
        "outputId": "52743a86-2fcf-45f2-ee73-2a31a8092a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-KRUnMUBbPf",
        "outputId": "747ac386-0d87-400f-eb07-e47fe75dc74a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/named-entity-recognition\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/named-entity-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script to download the dataset"
      ],
      "metadata": {
        "id": "vBJSfDunx95H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNZ4bTotZr8p",
        "outputId": "66562437-3a69-4a0c-a5b2-179035714ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BIOBERT_DATA not set; downloading to default path ('data').\n",
            "--2023-05-17 05:30:16--  http://nlp.dmis.korea.edu/projects/biobert-2020-checkpoints/datasets.tar.gz\n",
            "Resolving nlp.dmis.korea.edu (nlp.dmis.korea.edu)... 163.152.163.168\n",
            "Connecting to nlp.dmis.korea.edu (nlp.dmis.korea.edu)|163.152.163.168|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29610233 (28M) [application/x-gzip]\n",
            "Saving to: ‘./data.tar.gz’\n",
            "\n",
            "./data.tar.gz       100%[===================>]  28.24M   852KB/s    in 49s     \n",
            "\n",
            "2023-05-17 05:31:07 (585 KB/s) - ‘./data.tar.gz’ saved [29610233/29610233]\n",
            "\n",
            "datasets/\n",
            "datasets/RE/\n",
            "datasets/RE/GAD/\n",
            "datasets/RE/GAD/6/\n",
            "datasets/RE/GAD/6/test.tsv\n",
            "datasets/RE/GAD/6/dev.tsv\n",
            "datasets/RE/GAD/6/train.tsv\n",
            "datasets/RE/GAD/7/\n",
            "datasets/RE/GAD/7/test.tsv\n",
            "datasets/RE/GAD/7/dev.tsv\n",
            "datasets/RE/GAD/7/train.tsv\n",
            "datasets/RE/GAD/5/\n",
            "datasets/RE/GAD/5/test.tsv\n",
            "datasets/RE/GAD/5/dev.tsv\n",
            "datasets/RE/GAD/5/train.tsv\n",
            "datasets/RE/GAD/8/\n",
            "datasets/RE/GAD/8/test.tsv\n",
            "datasets/RE/GAD/8/dev.tsv\n",
            "datasets/RE/GAD/8/train.tsv\n",
            "datasets/RE/GAD/4/\n",
            "datasets/RE/GAD/4/test.tsv\n",
            "datasets/RE/GAD/4/dev.tsv\n",
            "datasets/RE/GAD/4/train.tsv\n",
            "datasets/RE/GAD/1/\n",
            "datasets/RE/GAD/1/test.tsv\n",
            "datasets/RE/GAD/1/dev.tsv\n",
            "datasets/RE/GAD/1/train.tsv\n",
            "datasets/RE/GAD/2/\n",
            "datasets/RE/GAD/2/test.tsv\n",
            "datasets/RE/GAD/2/dev.tsv\n",
            "datasets/RE/GAD/2/train.tsv\n",
            "datasets/RE/GAD/3/\n",
            "datasets/RE/GAD/3/test.tsv\n",
            "datasets/RE/GAD/3/dev.tsv\n",
            "datasets/RE/GAD/3/train.tsv\n",
            "datasets/RE/GAD/9/\n",
            "datasets/RE/GAD/9/test.tsv\n",
            "datasets/RE/GAD/9/dev.tsv\n",
            "datasets/RE/GAD/9/train.tsv\n",
            "datasets/RE/GAD/10/\n",
            "datasets/RE/GAD/10/test.tsv\n",
            "datasets/RE/GAD/10/dev.tsv\n",
            "datasets/RE/GAD/10/train.tsv\n",
            "datasets/RE/euadr/\n",
            "datasets/RE/euadr/6/\n",
            "datasets/RE/euadr/6/test.tsv\n",
            "datasets/RE/euadr/6/dev.tsv\n",
            "datasets/RE/euadr/6/train.tsv\n",
            "datasets/RE/euadr/7/\n",
            "datasets/RE/euadr/7/test.tsv\n",
            "datasets/RE/euadr/7/dev.tsv\n",
            "datasets/RE/euadr/7/train.tsv\n",
            "datasets/RE/euadr/5/\n",
            "datasets/RE/euadr/5/test.tsv\n",
            "datasets/RE/euadr/5/dev.tsv\n",
            "datasets/RE/euadr/5/train.tsv\n",
            "datasets/RE/euadr/8/\n",
            "datasets/RE/euadr/8/test.tsv\n",
            "datasets/RE/euadr/8/dev.tsv\n",
            "datasets/RE/euadr/8/train.tsv\n",
            "datasets/RE/euadr/4/\n",
            "datasets/RE/euadr/4/test.tsv\n",
            "datasets/RE/euadr/4/dev.tsv\n",
            "datasets/RE/euadr/4/train.tsv\n",
            "datasets/RE/euadr/1/\n",
            "datasets/RE/euadr/1/test.tsv\n",
            "datasets/RE/euadr/1/dev.tsv\n",
            "datasets/RE/euadr/1/train.tsv\n",
            "datasets/RE/euadr/2/\n",
            "datasets/RE/euadr/2/test.tsv\n",
            "datasets/RE/euadr/2/dev.tsv\n",
            "datasets/RE/euadr/2/train.tsv\n",
            "datasets/RE/euadr/3/\n",
            "datasets/RE/euadr/3/test.tsv\n",
            "datasets/RE/euadr/3/dev.tsv\n",
            "datasets/RE/euadr/3/train.tsv\n",
            "datasets/RE/euadr/9/\n",
            "datasets/RE/euadr/9/test.tsv\n",
            "datasets/RE/euadr/9/dev.tsv\n",
            "datasets/RE/euadr/9/train.tsv\n",
            "datasets/RE/euadr/10/\n",
            "datasets/RE/euadr/10/test.tsv\n",
            "datasets/RE/euadr/10/dev.tsv\n",
            "datasets/RE/euadr/10/train.tsv\n",
            "datasets/QA/\n",
            "datasets/QA/BioASQ/\n",
            "datasets/QA/BioASQ/6B1_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-7b.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-4.json\n",
            "datasets/QA/BioASQ/5B3_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-2.json\n",
            "datasets/QA/BioASQ/4B1_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-train-yesno-7b.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-5.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-2.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-2.json\n",
            "datasets/QA/BioASQ/4B4_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-3.json\n",
            "datasets/QA/BioASQ/6B3_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-3.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-5.json\n",
            "datasets/QA/BioASQ/BioASQ-test-yesno-7b.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-4b.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-1.json\n",
            "datasets/QA/BioASQ/6B5_golden.json\n",
            "datasets/QA/BioASQ/5B1_golden.json\n",
            "datasets/QA/BioASQ/4B5_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-3.json\n",
            "datasets/QA/BioASQ/7B_golden.json\n",
            "datasets/QA/BioASQ/5B4_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-6b.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-7b.json\n",
            "datasets/QA/BioASQ/SHA1.txt\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-1.json\n",
            "datasets/QA/BioASQ/BioASQ-train-factoid-5b.json\n",
            "datasets/QA/BioASQ/5B2_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-6b-4.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-5b-1.json\n",
            "datasets/QA/BioASQ/4B3_golden.json\n",
            "datasets/QA/BioASQ/6B2_golden.json\n",
            "datasets/QA/BioASQ/4B2_golden.json\n",
            "datasets/QA/BioASQ/6B4_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-5.json\n",
            "datasets/QA/BioASQ/5B5_golden.json\n",
            "datasets/QA/BioASQ/BioASQ-test-factoid-4b-4.json\n",
            "datasets/NER/\n",
            "datasets/NER/linnaeus/\n",
            "datasets/NER/linnaeus/devel.tsv\n",
            "datasets/NER/linnaeus/test.tsv\n",
            "datasets/NER/linnaeus/train_dev.tsv\n",
            "datasets/NER/linnaeus/train.tsv\n",
            "datasets/NER/BC2GM/\n",
            "datasets/NER/BC2GM/devel.tsv\n",
            "datasets/NER/BC2GM/test.tsv\n",
            "datasets/NER/BC2GM/train_dev.tsv\n",
            "datasets/NER/BC2GM/train.tsv\n",
            "datasets/NER/BC5CDR-disease/\n",
            "datasets/NER/BC5CDR-disease/devel.tsv\n",
            "datasets/NER/BC5CDR-disease/test.tsv\n",
            "datasets/NER/BC5CDR-disease/train_dev.tsv\n",
            "datasets/NER/BC5CDR-disease/train.tsv\n",
            "datasets/NER/NCBI-disease/\n",
            "datasets/NER/NCBI-disease/devel.tsv\n",
            "datasets/NER/NCBI-disease/test.tsv\n",
            "datasets/NER/NCBI-disease/train_dev.tsv\n",
            "datasets/NER/NCBI-disease/train.tsv\n",
            "datasets/NER/s800/\n",
            "datasets/NER/s800/devel.tsv\n",
            "datasets/NER/s800/test.tsv\n",
            "datasets/NER/s800/train_dev.tsv\n",
            "datasets/NER/s800/train.tsv\n",
            "datasets/NER/BC5CDR-chem/\n",
            "datasets/NER/BC5CDR-chem/devel.tsv\n",
            "datasets/NER/BC5CDR-chem/test.tsv\n",
            "datasets/NER/BC5CDR-chem/train_dev.tsv\n",
            "datasets/NER/BC5CDR-chem/train.tsv\n",
            "datasets/NER/JNLPBA/\n",
            "datasets/NER/JNLPBA/devel.tsv\n",
            "datasets/NER/JNLPBA/test.tsv\n",
            "datasets/NER/JNLPBA/train_dev.tsv\n",
            "datasets/NER/JNLPBA/train.tsv\n",
            "datasets/NER/BC4CHEMD/\n",
            "datasets/NER/BC4CHEMD/devel.tsv\n",
            "datasets/NER/BC4CHEMD/test.tsv\n",
            "datasets/NER/BC4CHEMD/train_dev.tsv\n",
            "datasets/NER/BC4CHEMD/train.tsv\n",
            "BioBERT dataset download done!\n"
          ]
        }
      ],
      "source": [
        "!bash download.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMR3dE3xbYvK",
        "outputId": "0c2937d2-125a-4914-8b99-6133cb553125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdatasets\u001b[0m/    \u001b[01;34membedding\u001b[0m/  \u001b[01;34mnamed-entity-recognition\u001b[0m/  README.md\n",
            "download.sh  LICENSE     \u001b[01;34mquestion-answering\u001b[0m/        \u001b[01;34mrelation-extraction\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-process the dataset"
      ],
      "metadata": {
        "id": "rYnGHqy4yEwo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-79_LfIomrei",
        "outputId": "89642cdb-4cf0-4b17-ae7e-59e544733cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****  NCBI-disease  Preprocessing Start *****\n",
            "Replacing Done\n",
            "Downloading: 100% 29.0/29.0 [00:00<00:00, 23.7kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 292kB/s]\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 3.65MB/s]\n",
            "Downloading: 100% 436k/436k [00:00<00:00, 5.41MB/s]\n",
            "*****  NCBI-disease  Preprocessing Done *****\n",
            "*****  BC5CDR-disease  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  BC5CDR-disease  Preprocessing Done *****\n",
            "*****  BC5CDR-chem  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  BC5CDR-chem  Preprocessing Done *****\n",
            "*****  BC4CHEMD  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  BC4CHEMD  Preprocessing Done *****\n",
            "*****  JNLPBA  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  JNLPBA  Preprocessing Done *****\n",
            "*****  BC2GM  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  BC2GM  Preprocessing Done *****\n",
            "*****  linnaeus  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  linnaeus  Preprocessing Done *****\n",
            "*****  s800  Preprocessing Start *****\n",
            "Replacing Done\n",
            "*****  s800  Preprocessing Done *****\n"
          ]
        }
      ],
      "source": [
        "!bash preprocess.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyOWPfrOE8HF",
        "outputId": "177e3190-a888-4468-f5ce-3685941e2188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B06PgtQqFIIF",
        "outputId": "4af0a8be-ebcb-44e2-9e34-3e362812515a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=7060413c43dc5268e121fad31a19b64c762d8ba72672a8f6d55f7a63488bcbde\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvsCVKRW8T20",
        "outputId": "b3018e71-d5a3-48c8-8b04-2ba763ccdef6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.20.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script to train the data"
      ],
      "metadata": {
        "id": "jIaLc6xUyQen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8pXC7QaYOsW",
        "outputId": "7852b816-f5e9-418d-f2d4-b5d91aeca47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 10:05:21.871735: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-30 10:05:23.362369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/30/2023 10:05:25 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/30/2023 10:05:25 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/runs/May30_10-05-25_96456844f8cd,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=30.0,\n",
            "output_dir=/content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=NCBI-disease,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/,\n",
            "save_steps=1000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=1,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "05/30/2023 10:05:32 - INFO - utils_ner -   Loading features from cached file /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/cached_train_dev_BertTokenizer_128\n",
            "05/30/2023 10:05:32 - INFO - utils_ner -   Loading features from cached file /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/cached_devel_BertTokenizer_128\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1023: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6355\n",
            "  Num Epochs = 30\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5970\n",
            "{'loss': 0.0436, 'learning_rate': 4.581239530988275e-05, 'epoch': 2.51}\n",
            "{'loss': 0.0065, 'learning_rate': 4.16247906197655e-05, 'epoch': 5.03}\n",
            " 17% 1000/5970 [11:25<55:52,  1.48it/s]Saving model checkpoint to /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-1000\n",
            "Configuration saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-1000/pytorch_model.bin\n",
            "{'loss': 0.0023, 'learning_rate': 3.7437185929648245e-05, 'epoch': 7.54}\n",
            "{'loss': 0.0014, 'learning_rate': 3.324958123953099e-05, 'epoch': 10.05}\n",
            " 34% 2000/5970 [23:01<45:25,  1.46it/s]Saving model checkpoint to /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-2000\n",
            "Configuration saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-2000/pytorch_model.bin\n",
            "{'loss': 0.0012, 'learning_rate': 2.906197654941374e-05, 'epoch': 12.56}\n",
            "{'loss': 0.0007, 'learning_rate': 2.4874371859296484e-05, 'epoch': 15.08}\n",
            " 50% 3000/5970 [34:37<34:00,  1.46it/s]Saving model checkpoint to /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-3000\n",
            "Configuration saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-3000/pytorch_model.bin\n",
            "{'loss': 0.0004, 'learning_rate': 2.0686767169179232e-05, 'epoch': 17.59}\n",
            "{'loss': 0.0004, 'learning_rate': 1.6499162479061976e-05, 'epoch': 20.1}\n",
            " 67% 4000/5970 [46:20<22:40,  1.45it/s]Saving model checkpoint to /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-4000\n",
            "Configuration saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-4000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-4000/pytorch_model.bin\n",
            "{'loss': 0.0003, 'learning_rate': 1.2311557788944725e-05, 'epoch': 22.61}\n",
            "{'loss': 0.0001, 'learning_rate': 8.123953098827471e-06, 'epoch': 25.13}\n",
            " 84% 5000/5970 [57:57<11:12,  1.44it/s]Saving model checkpoint to /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-5000\n",
            "Configuration saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-5000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/checkpoint-5000/pytorch_model.bin\n",
            "{'loss': 0.0001, 'learning_rate': 3.936348408710218e-06, 'epoch': 27.64}\n",
            "100% 5970/5970 [1:09:15<00:00,  1.63it/s]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 4155.1099, 'train_samples_per_second': 45.883, 'train_steps_per_second': 1.437, 'train_loss': 0.004770755608701826, 'epoch': 30.0}\n",
            "100% 5970/5970 [1:09:15<00:00,  1.44it/s]\n",
            "Saving model checkpoint to /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/\n",
            "Configuration saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/special_tokens_map.json\n",
            "05/30/2023 11:14:54 - INFO - __main__ -   *** Evaluate ***\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 923\n",
            "  Batch size = 8\n",
            "100% 116/116 [00:09<00:00, 11.62it/s]\n",
            "05/30/2023 11:15:04 - INFO - __main__ -   ***** Eval results *****\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_loss = 6.186569953570142e-05\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_precision = 1.0\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_recall = 1.0\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_f1 = 1.0\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_runtime = 10.035\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_samples_per_second = 91.978\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     eval_steps_per_second = 11.56\n",
            "05/30/2023 11:15:04 - INFO - __main__ -     epoch = 30.0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   Creating features from dataset file at /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   Writing example 0 of 942\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   *** Example ***\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   guid: test-1\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   tokens: [CLS] cluster ##ing of miss ##ense mutations in the at ##ax ##ia - te ##lang ##ie ##ct ##asi ##a gene in a s ##poradic t - cell le ##uka ##emia . [SEP]\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_ids: 101 10005 1158 1104 5529 22615 17157 1107 1103 1120 7897 1465 118 21359 19514 1663 5822 17506 1161 5565 1107 170 188 27695 189 118 2765 5837 12658 20504 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   label_ids: -100 2 -100 2 2 -100 2 2 2 0 -100 -100 1 1 -100 -100 -100 -100 -100 2 2 2 0 -100 1 1 1 1 -100 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   *** Example ***\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   guid: test-2\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   tokens: [CLS] at ##ax ##ia - te ##lang ##ie ##ct ##asi ##a ( a - t ) is a re ##cess ##ive multi - system disorder caused by mutations in the at ##m gene at 11 ##q ##22 - q ##23 ( re ##f . 3 ) . [SEP]\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_ids: 101 1120 7897 1465 118 21359 19514 1663 5822 17506 1161 113 170 118 189 114 1110 170 1231 22371 2109 4321 118 1449 8936 2416 1118 17157 1107 1103 1120 1306 5565 1120 1429 4426 20581 118 186 22737 113 1231 2087 119 124 114 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   label_ids: -100 0 -100 -100 1 1 -100 -100 -100 -100 -100 2 0 1 1 2 2 2 0 -100 -100 1 1 1 1 2 2 2 2 2 2 -100 2 2 2 -100 -100 2 2 -100 2 2 -100 2 2 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   *** Example ***\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   guid: test-3\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   tokens: [CLS] the risk of cancer , especially l ##ymph ##oid neo ##p ##lasia ##s , is substantially elevated in a - t patients and has long been associated with ch ##rom ##oso ##mal instability . [SEP]\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_ids: 101 1103 3187 1104 4182 117 2108 181 25698 7874 15242 1643 22992 1116 117 1110 12613 8208 1107 170 118 189 4420 1105 1144 1263 1151 2628 1114 22572 16071 22354 7435 20482 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   label_ids: -100 2 2 2 0 2 2 0 -100 -100 1 -100 -100 -100 2 2 2 2 2 0 1 1 2 2 2 2 2 2 2 2 -100 -100 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   *** Example ***\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   guid: test-4\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   tokens: [CLS] by anal ##ys ##ing t ##umour d ##na from patients with s ##poradic t - cell pro ##ly ##mp ##ho ##cy ##tic le ##uka ##emia ( t - p ##ll ) , a rare c ##lon ##al ma ##li ##gna ##ncy with similarities to a mature t - cell le ##uka ##emia seen in a - t , we demonstrate a high frequency of at ##m mutations in t - p ##ll . [SEP]\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_ids: 101 1118 24443 6834 1158 189 27226 173 1605 1121 4420 1114 188 27695 189 118 2765 5250 1193 8223 5114 3457 2941 5837 12658 20504 113 189 118 185 2339 114 117 170 4054 172 4934 1348 12477 2646 12149 7232 1114 12672 1106 170 9881 189 118 2765 5837 12658 20504 1562 1107 170 118 189 117 1195 10541 170 1344 5625 1104 1120 1306 17157 1107 189 118 185 2339 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   label_ids: -100 2 2 -100 -100 0 -100 2 -100 2 2 2 0 -100 1 1 1 1 -100 -100 -100 -100 -100 1 -100 -100 2 0 1 1 -100 2 2 2 2 0 -100 -100 1 -100 -100 -100 2 2 2 2 0 1 1 1 1 -100 -100 2 2 0 1 1 2 2 2 2 2 2 2 2 -100 2 2 0 1 1 -100 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   *** Example ***\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   guid: test-5\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   tokens: [CLS] in marked contrast to the at ##m mutation pattern in a - t , the most frequent n ##uc ##leo ##tide changes in this le ##uka ##emia were miss ##ense mutations . [SEP]\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_ids: 101 1107 3597 5014 1106 1103 1120 1306 17895 4844 1107 170 118 189 117 1103 1211 6539 183 21977 26918 23767 2607 1107 1142 5837 12658 20504 1127 5529 22615 17157 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/30/2023 11:15:04 - INFO - utils_ner -   label_ids: -100 2 2 2 2 2 2 -100 2 2 2 0 1 1 2 2 2 2 2 -100 -100 -100 2 2 2 0 -100 -100 2 2 -100 2 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "05/30/2023 11:15:06 - INFO - utils_ner -   Saving features into cached file /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/cached_test_BertTokenizer_128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 942\n",
            "  Batch size = 8\n",
            " 99% 117/118 [00:08<00:00, 14.41it/s]05/30/2023 11:15:18 - INFO - __main__ -   ***** Test results *****\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_loss = 0.11477562040090561\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_precision = 0.8544366899302094\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_recall = 0.8927083333333333\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_f1 = 0.8731533367294956\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_runtime = 10.1012\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_samples_per_second = 93.256\n",
            "05/30/2023 11:15:18 - INFO - __main__ -     test_steps_per_second = 11.682\n",
            "100% 118/118 [00:11<00:00, 10.04it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/named-entity-recognition/run_ner.py \\\n",
        "  --data_dir /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease \\\n",
        "  --labels /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/labels.txt \\\n",
        "  --model_name_or_path dmis-lab/biobert-base-cased-v1.1 \\\n",
        "  --output_dir /content/drive/MyDrive/Doctor_Robo/health_care/Fine-tune-BioBert/biobert-pytorch/datasets/NER/NCBI-disease/ \\\n",
        "  --max_seq_length 128 \\\n",
        "  --num_train_epochs 30 \\\n",
        "  --per_device_train_batch_size 32 \\\n",
        "  --save_steps 1000 \\\n",
        "  --seed 1 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_predict \\\n",
        "  --overwrite_output_dir"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}