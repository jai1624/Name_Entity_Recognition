{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","mount_file_id":"1dKGt8QfbDqg_AuVW3KOvmiUnp8_g0QfV","authorship_tag":"ABX9TyOowiiLkZ0q94kN5KtLFXZ5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d247322ff9784c08a209ad1c83551636":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b6b305038bc4af7aba8efd8ba35421b","IPY_MODEL_45cafb9c90764157bb305bda03ca398e","IPY_MODEL_d93d5247f1d547d9bd0a3611f4252d28"],"layout":"IPY_MODEL_4507dc1712874ce188f836dc624f1ac7"}},"1b6b305038bc4af7aba8efd8ba35421b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_452935a13ac548ba8de66e5d8c266590","placeholder":"​","style":"IPY_MODEL_92fd92aa25a343cb8977422656564f3f","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"45cafb9c90764157bb305bda03ca398e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d08bf92177e343a9a03bc8b4788fc7df","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ddcb7993efe42518e8b90c4fc520c49","value":231508}},"d93d5247f1d547d9bd0a3611f4252d28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16aa87dc385949b791496a3dc2b4929a","placeholder":"​","style":"IPY_MODEL_ba1991d1e89a4ccebf85c86f16516602","value":" 232k/232k [00:00&lt;00:00, 4.93MB/s]"}},"4507dc1712874ce188f836dc624f1ac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"452935a13ac548ba8de66e5d8c266590":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92fd92aa25a343cb8977422656564f3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d08bf92177e343a9a03bc8b4788fc7df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ddcb7993efe42518e8b90c4fc520c49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16aa87dc385949b791496a3dc2b4929a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba1991d1e89a4ccebf85c86f16516602":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52f19782abc34619864a2093d3ab2f3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec6d357e1acb41ffb1700c4c36c4c1f1","IPY_MODEL_de1b5f7c0667472d8286689136d3a166","IPY_MODEL_03dc92bc9033417daa57a2159975d3e0"],"layout":"IPY_MODEL_907554d121094bf183e78432263c9959"}},"ec6d357e1acb41ffb1700c4c36c4c1f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3997b42d1c264839873ee280dfaafeed","placeholder":"​","style":"IPY_MODEL_75e5053eb3d749b5b55567587fe55c2e","value":"Downloading (…)okenizer_config.json: 100%"}},"de1b5f7c0667472d8286689136d3a166":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68460cdbfbfd4184a45cb311a53b7552","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3433f18081e48b0b943a5983a861432","value":28}},"03dc92bc9033417daa57a2159975d3e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056b915f81794ce7a033f4f3bcf102f8","placeholder":"​","style":"IPY_MODEL_76c85fda0ece483e8ef0f2c3f0814ba8","value":" 28.0/28.0 [00:00&lt;00:00, 2.19kB/s]"}},"907554d121094bf183e78432263c9959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3997b42d1c264839873ee280dfaafeed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75e5053eb3d749b5b55567587fe55c2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68460cdbfbfd4184a45cb311a53b7552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3433f18081e48b0b943a5983a861432":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"056b915f81794ce7a033f4f3bcf102f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76c85fda0ece483e8ef0f2c3f0814ba8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64d9882c945e425686a1ec6cf80839bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e992d158ce34b80bea92d60d800ff5d","IPY_MODEL_a2a870ec08e4418fbb6bc23504951f33","IPY_MODEL_4003258504b046308704a4bbe9700a3e"],"layout":"IPY_MODEL_8734cd891c5a485086afa0cbea22ef27"}},"2e992d158ce34b80bea92d60d800ff5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b521d2a3f524d3eb439bf7b97bbed47","placeholder":"​","style":"IPY_MODEL_ecca9bfa9c584bc08829393e7ac6192b","value":"Downloading (…)lve/main/config.json: 100%"}},"a2a870ec08e4418fbb6bc23504951f33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_092c4c7def0e43e895d936f477b4d1dd","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48184219c023482c9a7dbb044052be97","value":570}},"4003258504b046308704a4bbe9700a3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e08e7645ef8649b2b93405b565a5f64e","placeholder":"​","style":"IPY_MODEL_b457ad0c8d924203a215f9a33dc07b21","value":" 570/570 [00:00&lt;00:00, 47.4kB/s]"}},"8734cd891c5a485086afa0cbea22ef27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b521d2a3f524d3eb439bf7b97bbed47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecca9bfa9c584bc08829393e7ac6192b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"092c4c7def0e43e895d936f477b4d1dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48184219c023482c9a7dbb044052be97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e08e7645ef8649b2b93405b565a5f64e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b457ad0c8d924203a215f9a33dc07b21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38584a1070194d56a049a286e6cf6d1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ae33f69ce41437885f56b8cf635f36d","IPY_MODEL_5e6998ca0c824314b0c55a17f89f8d48","IPY_MODEL_f474a32ea27c4984bb0a57adef59abab"],"layout":"IPY_MODEL_8c516e471b8b4b0c98e965a6882bba8d"}},"0ae33f69ce41437885f56b8cf635f36d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9e42a4de36f4a1f812a99e701a6b857","placeholder":"​","style":"IPY_MODEL_0d5f2d7df936481997f90e0f5b0764b1","value":"Downloading model.safetensors: 100%"}},"5e6998ca0c824314b0c55a17f89f8d48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e78390de448f49369b8cbb18a3e1d828","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ddf68537476a45bd9cab41547652e155","value":440449768}},"f474a32ea27c4984bb0a57adef59abab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e631f5c1cc34a54bb446e4e25f29092","placeholder":"​","style":"IPY_MODEL_068ff273f99a46bbbe7b2b09a973d380","value":" 440M/440M [00:02&lt;00:00, 204MB/s]"}},"8c516e471b8b4b0c98e965a6882bba8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9e42a4de36f4a1f812a99e701a6b857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d5f2d7df936481997f90e0f5b0764b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e78390de448f49369b8cbb18a3e1d828":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddf68537476a45bd9cab41547652e155":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e631f5c1cc34a54bb446e4e25f29092":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"068ff273f99a46bbbe7b2b09a973d380":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers seqeval[gpu]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AZizk5ODNsj","executionInfo":{"status":"ok","timestamp":1686665664935,"user_tz":-330,"elapsed":14740,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"b4ab326f-1406-4249-c3c2-231cb85f6a19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval[gpu]\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=bd1baa2240cb05a6891d33a2f33ed1b65c432b1324b3ca080d054fc1b580e613\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers, seqeval\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 seqeval-1.2.2 tokenizers-0.13.3 transformers-4.30.1\n"]}]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"6hafAUcKzAk0"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertConfig, BertForTokenClassification"],"metadata":{"id":"yoTs1wqkDXuS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAwmFUonDgzT","executionInfo":{"status":"ok","timestamp":1686665677210,"user_tz":-330,"elapsed":788,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"9ebf7a98-5548-46b1-9e62-240bcdd5ffc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["# Downloading and preprocessing the data"],"metadata":{"id":"iMeRW7dqzIW3"}},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Product_Feature_ner/data_bio_shuffled.csv\", encoding='unicode_escape')\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4l_qbQ00Dmyz","executionInfo":{"status":"ok","timestamp":1686665679971,"user_tz":-330,"elapsed":1412,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"5dd8c8b9-cce4-48cd-dd43-9638a45e7dac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sentence_id   words   labels\n","0            0                O\n","1            0     Fly        O\n","2            0      Me        O\n","3            0      to        O\n","4            0  Leanin  B-BRAND"],"text/html":["\n","  <div id=\"df-4fdbf9ca-081f-423f-889f-1d561810ac97\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>words</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td></td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Fly</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>Me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Leanin</td>\n","      <td>B-BRAND</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fdbf9ca-081f-423f-889f-1d561810ac97')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fdbf9ca-081f-423f-889f-1d561810ac97 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fdbf9ca-081f-423f-889f-1d561810ac97');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#Let's check how many sentences and words (and corresponding tags) there are in this dataset:\n","data.count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wjap-eJ9DuBn","executionInfo":{"status":"ok","timestamp":1686665690776,"user_tz":-330,"elapsed":439,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"96fde5c3-da92-48a3-999a-16b423f106cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["sentence_id    1139040\n","words          1139023\n","labels         1139040\n","dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#Let's have a look at the different NER tags, and their frequency:\n","print(\"Number of tags: {}\".format(len(data.labels.unique())))\n","frequencies = data.labels.value_counts()\n","frequencies"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwomoIt0DwvT","executionInfo":{"status":"ok","timestamp":1686665694467,"user_tz":-330,"elapsed":12,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"d1703c26-6f27-4e90-d56d-620715edbb75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of tags: 4\n"]},{"output_type":"execute_result","data":{"text/plain":["O          988665\n","B-BRAND     97677\n","I-BRAND     51157\n","-            1541\n","Name: labels, dtype: int64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["#Remove special characters\n","entities_to_remove = [\"-\"]\n","data = data[~data.labels.isin(entities_to_remove)]\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"HTPY2McVDzBU","executionInfo":{"status":"ok","timestamp":1686665696703,"user_tz":-330,"elapsed":632,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"31fe6690-a569-4862-a9b0-9f6eb522c1b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sentence_id   words   labels\n","0            0                O\n","1            0     Fly        O\n","2            0      Me        O\n","3            0      to        O\n","4            0  Leanin  B-BRAND"],"text/html":["\n","  <div id=\"df-a4d10655-13df-4c91-aa46-0a10b310cbcc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>words</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td></td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Fly</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>Me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Leanin</td>\n","      <td>B-BRAND</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d10655-13df-4c91-aa46-0a10b310cbcc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a4d10655-13df-4c91-aa46-0a10b310cbcc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a4d10655-13df-4c91-aa46-0a10b310cbcc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#There are 1 category tags, each with a \"beginning\" and \"inside\" variant, and the \"outside\" tag. Let's print them by frequency (highest to lowest):\n","tags = {}\n","for tag, count in zip(frequencies.index, frequencies):\n","    if tag != \"O\":\n","        if tag[2:5] not in tags.keys():\n","            tags[tag[2:5]] = count\n","        else:\n","            tags[tag[2:5]] += count\n","    continue\n","\n","print(sorted(tags.items(), key=lambda x: x[1], reverse=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7Gu7UTAEGlj","executionInfo":{"status":"ok","timestamp":1686665702896,"user_tz":-330,"elapsed":614,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"f31343db-370e-482b-ef37-5198c895b583"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('BRA', 148834), ('', 1541)]\n"]}]},{"cell_type":"code","source":["#create dictionary with numbers, indicies\n","labels_to_ids = {k: v for v, k in enumerate(data.labels.unique())}\n","ids_to_labels = {v: k for v, k in enumerate(data.labels.unique())}\n","labels_to_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zr04rAPTEJqC","executionInfo":{"status":"ok","timestamp":1686665705837,"user_tz":-330,"elapsed":5,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"af1f3167-1c91-41d6-af51-ac8ca16fc64e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'O': 0, 'B-BRAND': 1, 'I-BRAND': 2}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# fill nan values\n","data = data.fillna(method='ffill')\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"JyOkHBkKEPqW","executionInfo":{"status":"ok","timestamp":1686665708108,"user_tz":-330,"elapsed":372,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"ac54b7a4-52e3-43ea-c447-d1489543a758"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   sentence_id   words   labels\n","0            0                O\n","1            0     Fly        O\n","2            0      Me        O\n","3            0      to        O\n","4            0  Leanin  B-BRAND"],"text/html":["\n","  <div id=\"df-66a8a7c1-bd07-4cd1-80a9-219b6e16308a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>words</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td></td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Fly</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>Me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>to</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Leanin</td>\n","      <td>B-BRAND</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66a8a7c1-bd07-4cd1-80a9-219b6e16308a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-66a8a7c1-bd07-4cd1-80a9-219b6e16308a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-66a8a7c1-bd07-4cd1-80a9-219b6e16308a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# let's create a new column called \"sentence\" which groups the words by sentence\n","data['sentence'] = data[['sentence_id','words','labels']].groupby(['sentence_id'])['words'].transform(lambda x: ' '.join(x))\n","# let's also create a new column called \"word_labels\" which groups the tags by sentence\n","data['word_labels'] = data[['sentence_id','words','labels']].groupby(['sentence_id'])['labels'].transform(lambda x: ','.join(x))\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"3JEqczNrETNS","executionInfo":{"status":"ok","timestamp":1686665728815,"user_tz":-330,"elapsed":17699,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"0a0691cf-6b39-400a-8570-8804e9227fd4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         sentence_id      words   labels  \\\n","0                  0                   O   \n","1                  0        Fly        O   \n","2                  0         Me        O   \n","3                  0         to        O   \n","4                  0     Leanin  B-BRAND   \n","...              ...        ...      ...   \n","1139035        98828       Tape        O   \n","1139036        98828  Dispenser        O   \n","1139037        98828          ,        O   \n","1139038        98828      Smoky        O   \n","1139039        98828       Grey        O   \n","\n","                                                  sentence  \\\n","0          Fly Me to Leanin ' Tree the Moon - Josephine...   \n","1          Fly Me to Leanin ' Tree the Moon - Josephine...   \n","2          Fly Me to Leanin ' Tree the Moon - Josephine...   \n","3          Fly Me to Leanin ' Tree the Moon - Josephine...   \n","4          Fly Me to Leanin ' Tree the Moon - Josephine...   \n","...                                                    ...   \n","1139035  Comix B2250 Office Desk Organizer , 8 Componen...   \n","1139036  Comix B2250 Office Desk Organizer , 8 Componen...   \n","1139037  Comix B2250 Office Desk Organizer , 8 Componen...   \n","1139038  Comix B2250 Office Desk Organizer , 8 Componen...   \n","1139039  Comix B2250 Office Desk Organizer , 8 Componen...   \n","\n","                                           word_labels  \n","0        O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","1        O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","2        O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","3        O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","4        O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","...                                                ...  \n","1139035        B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","1139036        B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","1139037        B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","1139038        B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","1139039        B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","\n","[1137499 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-899eb88b-384b-4cfe-8a0c-7fa0833eb541\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>words</th>\n","      <th>labels</th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td></td>\n","      <td>O</td>\n","      <td>Fly Me to Leanin ' Tree the Moon - Josephine...</td>\n","      <td>O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Fly</td>\n","      <td>O</td>\n","      <td>Fly Me to Leanin ' Tree the Moon - Josephine...</td>\n","      <td>O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>Me</td>\n","      <td>O</td>\n","      <td>Fly Me to Leanin ' Tree the Moon - Josephine...</td>\n","      <td>O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>to</td>\n","      <td>O</td>\n","      <td>Fly Me to Leanin ' Tree the Moon - Josephine...</td>\n","      <td>O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Leanin</td>\n","      <td>B-BRAND</td>\n","      <td>Fly Me to Leanin ' Tree the Moon - Josephine...</td>\n","      <td>O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1139035</th>\n","      <td>98828</td>\n","      <td>Tape</td>\n","      <td>O</td>\n","      <td>Comix B2250 Office Desk Organizer , 8 Componen...</td>\n","      <td>B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>1139036</th>\n","      <td>98828</td>\n","      <td>Dispenser</td>\n","      <td>O</td>\n","      <td>Comix B2250 Office Desk Organizer , 8 Componen...</td>\n","      <td>B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>1139037</th>\n","      <td>98828</td>\n","      <td>,</td>\n","      <td>O</td>\n","      <td>Comix B2250 Office Desk Organizer , 8 Componen...</td>\n","      <td>B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>1139038</th>\n","      <td>98828</td>\n","      <td>Smoky</td>\n","      <td>O</td>\n","      <td>Comix B2250 Office Desk Organizer , 8 Componen...</td>\n","      <td>B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>1139039</th>\n","      <td>98828</td>\n","      <td>Grey</td>\n","      <td>O</td>\n","      <td>Comix B2250 Office Desk Organizer , 8 Componen...</td>\n","      <td>B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1137499 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-899eb88b-384b-4cfe-8a0c-7fa0833eb541')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-899eb88b-384b-4cfe-8a0c-7fa0833eb541 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-899eb88b-384b-4cfe-8a0c-7fa0833eb541');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#select sentence,labels column and drop duplicates\n","data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":249},"id":"hbqMUoI2E82z","executionInfo":{"status":"ok","timestamp":1686665750779,"user_tz":-330,"elapsed":628,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"9dfdee75-81a9-47e2-9f55-5d10d9a5f084"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            sentence  \\\n","0    Fly Me to Leanin ' Tree the Moon - Josephine...   \n","1    Instant Breakfast Complete Nutritional Class...   \n","2  RI Novelty Slam Dunk Basketball Gumball Dispen...   \n","3    Spiced Chai Novus Black Tea , 12 - Count Tea...   \n","4  Mint Julep Cocktail Mixer by Woodford Reserve ...   \n","\n","                                     word_labels  \n","0  O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","1            O,O,O,O,O,O,O,B-BRAND,O,O,O,O,O,O,O  \n","2                  B-BRAND,I-BRAND,O,O,O,O,O,O,O  \n","3        O,O,O,B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O  \n","4        O,O,O,O,O,B-BRAND,I-BRAND,O,O,O,O,O,O,O  "],"text/html":["\n","  <div id=\"df-273a1f3f-ca99-4ad5-8e6f-7246d409f66b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>word_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Fly Me to Leanin ' Tree the Moon - Josephine...</td>\n","      <td>O,O,O,O,B-BRAND,I-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Instant Breakfast Complete Nutritional Class...</td>\n","      <td>O,O,O,O,O,O,O,B-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RI Novelty Slam Dunk Basketball Gumball Dispen...</td>\n","      <td>B-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Spiced Chai Novus Black Tea , 12 - Count Tea...</td>\n","      <td>O,O,O,B-BRAND,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Mint Julep Cocktail Mixer by Woodford Reserve ...</td>\n","      <td>O,O,O,O,O,B-BRAND,I-BRAND,O,O,O,O,O,O,O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-273a1f3f-ca99-4ad5-8e6f-7246d409f66b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-273a1f3f-ca99-4ad5-8e6f-7246d409f66b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-273a1f3f-ca99-4ad5-8e6f-7246d409f66b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["# Cross verify the sentence & label"],"metadata":{"id":"JVQrz4Od08yN"}},{"cell_type":"code","source":["len(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQrOD4-UFHSC","executionInfo":{"status":"ok","timestamp":1686665753654,"user_tz":-330,"elapsed":3,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"2bcb578a-d46d-4f96-a7d8-4d18ae99b708"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["98820"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["data.iloc[41].sentence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kcvH0oAnFKg1","executionInfo":{"status":"ok","timestamp":1686665755738,"user_tz":-330,"elapsed":11,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"39109304-29c5-487c-904a-ead92e31ddc3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'  Alphabet Pasta , 7 - Ounce ( Pack La Moderna of 3 )'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["data.sentence = data.sentence.str.strip()"],"metadata":{"id":"tKdk3e-_FP6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.iloc[41].word_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VQvVHYk5FWJh","executionInfo":{"status":"ok","timestamp":1686665759542,"user_tz":-330,"elapsed":9,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"09c9958b-8c4a-448e-9616-bf2d4233626e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'O,O,O,O,O,O,O,O,O,B-BRAND,I-BRAND,O,O,O'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Preparing the dataset & dataloader"],"metadata":{"id":"bZjxI70w1CBs"}},{"cell_type":"code","source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 4\n","VALID_BATCH_SIZE = 2\n","EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","MAX_GRAD_NORM = 10\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["d247322ff9784c08a209ad1c83551636","1b6b305038bc4af7aba8efd8ba35421b","45cafb9c90764157bb305bda03ca398e","d93d5247f1d547d9bd0a3611f4252d28","4507dc1712874ce188f836dc624f1ac7","452935a13ac548ba8de66e5d8c266590","92fd92aa25a343cb8977422656564f3f","d08bf92177e343a9a03bc8b4788fc7df","3ddcb7993efe42518e8b90c4fc520c49","16aa87dc385949b791496a3dc2b4929a","ba1991d1e89a4ccebf85c86f16516602","52f19782abc34619864a2093d3ab2f3f","ec6d357e1acb41ffb1700c4c36c4c1f1","de1b5f7c0667472d8286689136d3a166","03dc92bc9033417daa57a2159975d3e0","907554d121094bf183e78432263c9959","3997b42d1c264839873ee280dfaafeed","75e5053eb3d749b5b55567587fe55c2e","68460cdbfbfd4184a45cb311a53b7552","b3433f18081e48b0b943a5983a861432","056b915f81794ce7a033f4f3bcf102f8","76c85fda0ece483e8ef0f2c3f0814ba8","64d9882c945e425686a1ec6cf80839bb","2e992d158ce34b80bea92d60d800ff5d","a2a870ec08e4418fbb6bc23504951f33","4003258504b046308704a4bbe9700a3e","8734cd891c5a485086afa0cbea22ef27","5b521d2a3f524d3eb439bf7b97bbed47","ecca9bfa9c584bc08829393e7ac6192b","092c4c7def0e43e895d936f477b4d1dd","48184219c023482c9a7dbb044052be97","e08e7645ef8649b2b93405b565a5f64e","b457ad0c8d924203a215f9a33dc07b21"]},"id":"mrk_LeJBFYRC","executionInfo":{"status":"ok","timestamp":1686665762845,"user_tz":-330,"elapsed":1149,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"ce7c1f70-356c-48bc-ab91-29e1b0aa4432"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d247322ff9784c08a209ad1c83551636"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52f19782abc34619864a2093d3ab2f3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64d9882c945e425686a1ec6cf80839bb"}},"metadata":{}}]},{"cell_type":"code","source":["def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n","    \"\"\"\n","    Word piece tokenization makes it difficult to match word labels\n","    back up with individual word pieces. This function tokenizes each\n","    word one at a time so that it is easier to preserve the correct\n","    label for each subword. It is, of course, a bit slower in processing\n","    time, but it will help our model achieve higher accuracy.\n","    \"\"\"\n","\n","    tokenized_sentence = []\n","    labels = []\n","\n","    sentence = sentence.strip()\n","\n","    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = tokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","\n","    return tokenized_sentence, labels"],"metadata":{"id":"FfMdW-QLFfxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#dataset class (which transforms examples of a dataframe to PyTorch tensors\n","class dataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        # step 1: tokenize (and adapt corresponding labels)\n","        sentence = self.data.sentence[index]\n","        word_labels = self.data.word_labels[index]\n","        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n","\n","        # step 2: add special tokens (and corresponding labels)\n","        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n","        labels.insert(0, \"O\") # add outside label for [CLS] token\n","        labels.insert(-1, \"O\") # add outside label for [SEP] token\n","\n","        # step 3: truncating/padding\n","        maxlen = self.max_len\n","\n","        if (len(tokenized_sentence) > maxlen):\n","          # truncate\n","          tokenized_sentence = tokenized_sentence[:maxlen]\n","          labels = labels[:maxlen]\n","        else:\n","          # pad\n","          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n","          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n","\n","        # step 4: obtain the attention mask\n","        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n","\n","        # step 5: convert tokens to input ids\n","        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n","\n","        label_ids = [label2id[label] for label in labels]\n","        # the following line is deprecated\n","        #label_ids = [label if label != 0 else -100 for label in label_ids]\n","\n","        return {\n","              'ids': torch.tensor(ids, dtype=torch.long),\n","              'mask': torch.tensor(attn_mask, dtype=torch.long),\n","              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n","              'targets': torch.tensor(label_ids, dtype=torch.long)\n","        }\n","\n","    def __len__(self):\n","        return self.len"],"metadata":{"id":"wwdcWJQbFxay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create 2 datasets, one for training and one for testing. Let's use a 80/20 split\n","train_size = 0.8\n","train_dataset = data.sample(frac=train_size,random_state=200)\n","test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(data.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n","testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hi9usAjfFy0z","executionInfo":{"status":"ok","timestamp":1686665770266,"user_tz":-330,"elapsed":6,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"452a7d28-c37d-4f2b-a710-2d3b72dd647c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FULL Dataset: (98820, 2)\n","TRAIN Dataset: (79056, 2)\n","TEST Dataset: (19764, 2)\n"]}]},{"cell_type":"code","source":["training_set[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlQIP3a2F0Oh","executionInfo":{"status":"ok","timestamp":1686665772721,"user_tz":-330,"elapsed":586,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"90a43e75-c3d6-4f3f-f9a8-0a94eac30e77"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'ids': tensor([  101,  4086,  4589,  1998,  4589,  6546,  5909,  9389,  1011,  1048,\n","          1005,  8680,  9496,  2368,  1011,  2340,  1012,  1020, 11472,   102,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0]),\n"," 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'targets': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0])}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["training_set[0][\"ids\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ol0XewWyF32S","executionInfo":{"status":"ok","timestamp":1686665774446,"user_tz":-330,"elapsed":8,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"3dcd0f18-2e5c-411b-df0d-d37363e31489"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  101,  4086,  4589,  1998,  4589,  6546,  5909,  9389,  1011,  1048,\n","         1005,  8680,  9496,  2368,  1011,  2340,  1012,  1020, 11472,   102,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# print the first 30 tokens and corresponding labels\n","for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:30]), training_set[0][\"targets\"][:30]):\n","  print('{0:10}  {1}'.format(token, id2label[label.item()]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8ZjidLIF6cC","executionInfo":{"status":"ok","timestamp":1686665776295,"user_tz":-330,"elapsed":3,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"0b48394e-8062-41d6-9175-202eee84d9b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS]       O\n","sweet       O\n","orange      O\n","and         O\n","orange      O\n","flower      O\n","fruit       O\n","jam         O\n","-           O\n","l           B-BRAND\n","'           B-BRAND\n","epic        B-BRAND\n","##uri       B-BRAND\n","##en        B-BRAND\n","-           O\n","11          O\n",".           O\n","6           O\n","oz          O\n","[SEP]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n","[PAD]       O\n"]}]},{"cell_type":"code","source":["#define pytorch loaders\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"],"metadata":{"id":"rgq1m66qF71y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Defining the model"],"metadata":{"id":"tS2y0VGZ1VH8"}},{"cell_type":"code","source":["model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n","                                                   num_labels=len(id2label),\n","                                                   id2label=id2label,\n","                                                   label2id=label2id)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":891,"referenced_widgets":["38584a1070194d56a049a286e6cf6d1d","0ae33f69ce41437885f56b8cf635f36d","5e6998ca0c824314b0c55a17f89f8d48","f474a32ea27c4984bb0a57adef59abab","8c516e471b8b4b0c98e965a6882bba8d","e9e42a4de36f4a1f812a99e701a6b857","0d5f2d7df936481997f90e0f5b0764b1","e78390de448f49369b8cbb18a3e1d828","ddf68537476a45bd9cab41547652e155","6e631f5c1cc34a54bb446e4e25f29092","068ff273f99a46bbbe7b2b09a973d380"]},"id":"NWYmVpbQF_Di","executionInfo":{"status":"ok","timestamp":1686665791105,"user_tz":-330,"elapsed":9534,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"2a8d7c99-54f0-46a9-fd70-69cad411e5f6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38584a1070194d56a049a286e6cf6d1d"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["# Training the model"],"metadata":{"id":"1Tl7QitU1ccG"}},{"cell_type":"code","source":["ids = training_set[0][\"ids\"].unsqueeze(0)\n","mask = training_set[0][\"mask\"].unsqueeze(0)\n","targets = training_set[0][\"targets\"].unsqueeze(0)\n","ids = ids.to(device)\n","mask = mask.to(device)\n","targets = targets.to(device)\n","outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n","initial_loss = outputs[0]\n","initial_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gLuhF-ymGBJC","executionInfo":{"status":"ok","timestamp":1686665796882,"user_tz":-330,"elapsed":3640,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"0d19d854-b3f3-4fec-b507-9c89b40e68d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9866, device='cuda:0', grad_fn=<NllLossBackward0>)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["#check the shape of batch_size, sequence_length, num_lables\n","tr_logits = outputs[1]\n","tr_logits.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Sl8plymGDpz","executionInfo":{"status":"ok","timestamp":1686665798853,"user_tz":-330,"elapsed":7,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"c830ce0d-cb78-4bf6-8ecd-f643169f2b54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 128, 3])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"],"metadata":{"id":"31u0zZQvGGRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Defining the training function on the 80% of the dataset for tuning the bert model\n","def train(epoch):\n","    tr_loss, tr_accuracy = 0, 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    tr_preds, tr_labels = [], []\n","    # put model in training mode\n","    model.train()\n","\n","    for idx, batch in enumerate(training_loader):\n","\n","        ids = batch['ids'].to(device, dtype = torch.long)\n","        mask = batch['mask'].to(device, dtype = torch.long)\n","        targets = batch['targets'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n","        loss, tr_logits = outputs.loss, outputs.logits\n","        tr_loss += loss.item()\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","\n","        if idx % 100==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            print(f\"Training loss per 100 training steps: {loss_step}\")\n","\n","        # compute training accuracy\n","        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n","        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n","        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n","        targets = torch.masked_select(flattened_targets, active_accuracy)\n","        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","\n","        tr_preds.extend(predictions)\n","        tr_labels.extend(targets)\n","\n","        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n","        tr_accuracy += tmp_tr_accuracy\n","\n","        # gradient clipping\n","        torch.nn.utils.clip_grad_norm_(\n","            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n","        )\n","\n","        # backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    tr_accuracy = tr_accuracy / nb_tr_steps\n","    print(f\"Training loss epoch: {epoch_loss}\")\n","    print(f\"Training accuracy epoch: {tr_accuracy}\")"],"metadata":{"id":"MsNTsiLeGGrC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","    print(f\"Training epoch: {epoch + 1}\")\n","    train(epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UujfqJHlGIqS","executionInfo":{"status":"ok","timestamp":1686666867289,"user_tz":-330,"elapsed":1062686,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"a233eb21-a5be-42a4-989c-6b5f03dc746f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training epoch: 1\n","Training loss per 100 training steps: 0.9611827731132507\n","Training loss per 100 training steps: 0.12757378444075584\n","Training loss per 100 training steps: 0.09174270281077024\n","Training loss per 100 training steps: 0.07852612321336205\n","Training loss per 100 training steps: 0.07137204942634873\n","Training loss per 100 training steps: 0.06632383660359416\n","Training loss per 100 training steps: 0.06257253891157727\n","Training loss per 100 training steps: 0.05968290543749652\n","Training loss per 100 training steps: 0.05753287664741352\n","Training loss per 100 training steps: 0.05560714961107113\n","Training loss per 100 training steps: 0.05374273946313383\n","Training loss per 100 training steps: 0.052448324363451995\n","Training loss per 100 training steps: 0.05129660553857995\n","Training loss per 100 training steps: 0.05028375745074484\n","Training loss per 100 training steps: 0.04927687790593149\n","Training loss per 100 training steps: 0.048282429237765004\n","Training loss per 100 training steps: 0.04736531385308426\n","Training loss per 100 training steps: 0.04677638395151221\n","Training loss per 100 training steps: 0.046045205476737766\n","Training loss per 100 training steps: 0.04543889805709827\n","Training loss per 100 training steps: 0.044826052292645246\n","Training loss per 100 training steps: 0.04436841501837959\n","Training loss per 100 training steps: 0.043938402365554616\n","Training loss per 100 training steps: 0.0434839305197128\n","Training loss per 100 training steps: 0.04301695310251197\n","Training loss per 100 training steps: 0.04251603009357977\n","Training loss per 100 training steps: 0.04204014753790337\n","Training loss per 100 training steps: 0.04163313264207227\n","Training loss per 100 training steps: 0.04130476948754282\n","Training loss per 100 training steps: 0.04099840861904091\n","Training loss per 100 training steps: 0.04063893817967224\n","Training loss per 100 training steps: 0.040326329820598084\n","Training loss per 100 training steps: 0.04008706940555644\n","Training loss per 100 training steps: 0.03981085937335902\n","Training loss per 100 training steps: 0.03953247196984419\n","Training loss per 100 training steps: 0.03927149866957412\n","Training loss per 100 training steps: 0.03908563371757043\n","Training loss per 100 training steps: 0.03870539106763306\n","Training loss per 100 training steps: 0.038365216998388796\n","Training loss per 100 training steps: 0.03813527759044725\n","Training loss per 100 training steps: 0.0378334227152368\n","Training loss per 100 training steps: 0.0376443309684222\n","Training loss per 100 training steps: 0.037491218738813885\n","Training loss per 100 training steps: 0.0373082868968152\n","Training loss per 100 training steps: 0.0370603050305251\n","Training loss per 100 training steps: 0.03681644201162814\n","Training loss per 100 training steps: 0.03664370809732925\n","Training loss per 100 training steps: 0.03650404165028001\n","Training loss per 100 training steps: 0.0362707432308051\n","Training loss per 100 training steps: 0.03605379655704866\n","Training loss per 100 training steps: 0.03584737261920017\n","Training loss per 100 training steps: 0.03567461833207003\n","Training loss per 100 training steps: 0.035478297252628084\n","Training loss per 100 training steps: 0.03532458068101079\n","Training loss per 100 training steps: 0.03515265667708437\n","Training loss per 100 training steps: 0.03498510513770421\n","Training loss per 100 training steps: 0.03479316906998201\n","Training loss per 100 training steps: 0.03464971843063361\n","Training loss per 100 training steps: 0.034488884540917884\n","Training loss per 100 training steps: 0.03433752739402707\n","Training loss per 100 training steps: 0.034183263918516824\n","Training loss per 100 training steps: 0.03403909958664244\n","Training loss per 100 training steps: 0.0339155872879585\n","Training loss per 100 training steps: 0.03379922778848331\n","Training loss per 100 training steps: 0.03365764197778644\n","Training loss per 100 training steps: 0.03350925234390242\n","Training loss per 100 training steps: 0.03342694905791119\n","Training loss per 100 training steps: 0.03334664098732618\n","Training loss per 100 training steps: 0.033210083055049085\n","Training loss per 100 training steps: 0.033074674507898735\n","Training loss per 100 training steps: 0.03290484040959142\n","Training loss per 100 training steps: 0.032832880571530866\n","Training loss per 100 training steps: 0.0327045119207588\n","Training loss per 100 training steps: 0.032608179230030065\n","Training loss per 100 training steps: 0.0324987542190944\n","Training loss per 100 training steps: 0.03236250254479092\n","Training loss per 100 training steps: 0.032226146132016985\n","Training loss per 100 training steps: 0.032120172059609826\n","Training loss per 100 training steps: 0.03202434454340136\n","Training loss per 100 training steps: 0.03193489715886083\n","Training loss per 100 training steps: 0.0318055617464697\n","Training loss per 100 training steps: 0.03171241259698258\n","Training loss per 100 training steps: 0.0316243361898291\n","Training loss per 100 training steps: 0.03152398755479112\n","Training loss per 100 training steps: 0.03145997761714088\n","Training loss per 100 training steps: 0.03135143488683843\n","Training loss per 100 training steps: 0.031267395993962006\n","Training loss per 100 training steps: 0.03119949054465273\n","Training loss per 100 training steps: 0.03112146620866023\n","Training loss per 100 training steps: 0.03104299202352064\n","Training loss per 100 training steps: 0.030967664147358635\n","Training loss per 100 training steps: 0.03086625427918071\n","Training loss per 100 training steps: 0.030789752499839708\n","Training loss per 100 training steps: 0.030720260157645386\n","Training loss per 100 training steps: 0.030629787609001837\n","Training loss per 100 training steps: 0.03057019782190414\n","Training loss per 100 training steps: 0.030528108500945374\n","Training loss per 100 training steps: 0.030438725393438386\n","Training loss per 100 training steps: 0.030391222685076137\n","Training loss per 100 training steps: 0.030299525805280562\n","Training loss per 100 training steps: 0.030249855791757947\n","Training loss per 100 training steps: 0.03017910944040715\n","Training loss per 100 training steps: 0.03012447720539842\n","Training loss per 100 training steps: 0.030065009368219837\n","Training loss per 100 training steps: 0.02999807183870333\n","Training loss per 100 training steps: 0.029919236442261757\n","Training loss per 100 training steps: 0.029858786636765732\n","Training loss per 100 training steps: 0.02980357527200609\n","Training loss per 100 training steps: 0.029713254297385746\n","Training loss per 100 training steps: 0.029653567800742336\n","Training loss per 100 training steps: 0.02961146718865468\n","Training loss per 100 training steps: 0.029538701153508803\n","Training loss per 100 training steps: 0.029469869141681433\n","Training loss per 100 training steps: 0.029398899250513005\n","Training loss per 100 training steps: 0.029352315247186546\n","Training loss per 100 training steps: 0.029293813429263585\n","Training loss per 100 training steps: 0.02925128825019105\n","Training loss per 100 training steps: 0.029195353758408198\n","Training loss per 100 training steps: 0.029148718772322914\n","Training loss per 100 training steps: 0.029110904398608087\n","Training loss per 100 training steps: 0.02904340556404472\n","Training loss per 100 training steps: 0.029003395786095707\n","Training loss per 100 training steps: 0.028960136331191672\n","Training loss per 100 training steps: 0.028900430316693232\n","Training loss per 100 training steps: 0.028849992678817184\n","Training loss per 100 training steps: 0.02881099002651071\n","Training loss per 100 training steps: 0.028773179540033188\n","Training loss per 100 training steps: 0.028729992672576563\n","Training loss per 100 training steps: 0.028666714301381794\n","Training loss per 100 training steps: 0.028611102624291434\n","Training loss per 100 training steps: 0.02855884652265408\n","Training loss per 100 training steps: 0.02851430437524469\n","Training loss per 100 training steps: 0.028451498616644113\n","Training loss per 100 training steps: 0.02840559071818916\n","Training loss per 100 training steps: 0.02835743210949996\n","Training loss per 100 training steps: 0.02832526091870306\n","Training loss per 100 training steps: 0.02830516438432458\n","Training loss per 100 training steps: 0.0282527087270757\n","Training loss per 100 training steps: 0.028222073360590745\n","Training loss per 100 training steps: 0.028180046390074643\n","Training loss per 100 training steps: 0.02810915924351481\n","Training loss per 100 training steps: 0.02805285275423115\n","Training loss per 100 training steps: 0.027986653785120743\n","Training loss per 100 training steps: 0.027936964664546635\n","Training loss per 100 training steps: 0.02790193666336217\n","Training loss per 100 training steps: 0.027853718197780382\n","Training loss per 100 training steps: 0.027810536635578195\n","Training loss per 100 training steps: 0.02777575822197539\n","Training loss per 100 training steps: 0.027723265894489577\n","Training loss per 100 training steps: 0.027683772584229983\n","Training loss per 100 training steps: 0.02766083148782886\n","Training loss per 100 training steps: 0.02763600414339009\n","Training loss per 100 training steps: 0.02760616583441876\n","Training loss per 100 training steps: 0.02756236869948848\n","Training loss per 100 training steps: 0.027527560737646117\n","Training loss per 100 training steps: 0.027492150277742943\n","Training loss per 100 training steps: 0.027461342568817673\n","Training loss per 100 training steps: 0.027403724049876704\n","Training loss per 100 training steps: 0.027354085711810288\n","Training loss per 100 training steps: 0.02731302811338786\n","Training loss per 100 training steps: 0.027278039694008698\n","Training loss per 100 training steps: 0.027233658949467984\n","Training loss per 100 training steps: 0.027192908235275808\n","Training loss per 100 training steps: 0.027172648797428336\n","Training loss per 100 training steps: 0.027123670029697768\n","Training loss per 100 training steps: 0.027083524385622438\n","Training loss per 100 training steps: 0.027052151794711633\n","Training loss per 100 training steps: 0.02701984598871069\n","Training loss per 100 training steps: 0.02698228937126196\n","Training loss per 100 training steps: 0.026989945181648538\n","Training loss per 100 training steps: 0.026968677307498915\n","Training loss per 100 training steps: 0.026923499524019453\n","Training loss per 100 training steps: 0.026881289540967992\n","Training loss per 100 training steps: 0.02684734235650373\n","Training loss per 100 training steps: 0.026805926691092073\n","Training loss per 100 training steps: 0.02678013576023317\n","Training loss per 100 training steps: 0.026738873431387374\n","Training loss per 100 training steps: 0.02670833541799696\n","Training loss per 100 training steps: 0.026696801839053565\n","Training loss per 100 training steps: 0.02667434176326678\n","Training loss per 100 training steps: 0.026642610899657863\n","Training loss per 100 training steps: 0.026608304069624705\n","Training loss per 100 training steps: 0.026571403368489073\n","Training loss per 100 training steps: 0.026552061341730875\n","Training loss per 100 training steps: 0.026517636004568284\n","Training loss per 100 training steps: 0.026480147768590305\n","Training loss per 100 training steps: 0.026434970897020633\n","Training loss per 100 training steps: 0.026404890410908766\n","Training loss per 100 training steps: 0.02638582751632623\n","Training loss per 100 training steps: 0.02634913740289817\n","Training loss per 100 training steps: 0.026316236203881356\n","Training loss per 100 training steps: 0.02630181431500548\n","Training loss per 100 training steps: 0.026277082027737157\n","Training loss per 100 training steps: 0.026255138926255788\n","Training loss per 100 training steps: 0.026240101087533396\n","Training loss per 100 training steps: 0.026201921364968846\n","Training loss per 100 training steps: 0.026186288963313136\n","Training loss per 100 training steps: 0.02616427336785859\n","Training loss epoch: 0.026143534907893888\n","Training accuracy epoch: 0.9328563807649253\n"]}]},{"cell_type":"code","source":["def valid(model, testing_loader):\n","    # put model in evaluation mode\n","    model.eval()\n","\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_examples, nb_eval_steps = 0, 0\n","    eval_preds, eval_labels = [], []\n","\n","    with torch.no_grad():\n","        for idx, batch in enumerate(testing_loader):\n","\n","            ids = batch['ids'].to(device, dtype = torch.long)\n","            mask = batch['mask'].to(device, dtype = torch.long)\n","            targets = batch['targets'].to(device, dtype = torch.long)\n","\n","            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n","            loss, eval_logits = outputs.loss, outputs.logits\n","\n","            eval_loss += loss.item()\n","\n","            nb_eval_steps += 1\n","            nb_eval_examples += targets.size(0)\n","\n","            if idx % 100==0:\n","                loss_step = eval_loss/nb_eval_steps\n","                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n","\n","            # compute evaluation accuracy\n","            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n","            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n","            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n","            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n","            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n","            targets = torch.masked_select(flattened_targets, active_accuracy)\n","            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n","\n","            eval_labels.extend(targets)\n","            eval_preds.extend(predictions)\n","\n","            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n","            eval_accuracy += tmp_eval_accuracy\n","\n","    #print(eval_labels)\n","    #print(eval_preds)\n","\n","    labels = [id2label[id.item()] for id in eval_labels]\n","    predictions = [id2label[id.item()] for id in eval_preds]\n","\n","    #print(labels)\n","    #print(predictions)\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    eval_accuracy = eval_accuracy / nb_eval_steps\n","    print(f\"Validation Loss: {eval_loss}\")\n","    print(f\"Validation Accuracy: {eval_accuracy}\")\n","\n","    return labels, predictions"],"metadata":{"id":"RW8lwSuIGTgD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels, predictions = valid(model, testing_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3EwcbzNI8-E","executionInfo":{"status":"ok","timestamp":1686667051662,"user_tz":-330,"elapsed":153071,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"e65026fc-56ad-431d-fcd3-4ab4bbcbd6be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation loss per 100 evaluation steps: 0.0052770585753023624\n","Validation loss per 100 evaluation steps: 0.01855647478005987\n","Validation loss per 100 evaluation steps: 0.01978789855664091\n","Validation loss per 100 evaluation steps: 0.019093280714834834\n","Validation loss per 100 evaluation steps: 0.018793671648177735\n","Validation loss per 100 evaluation steps: 0.018281491464545333\n","Validation loss per 100 evaluation steps: 0.018131976321552876\n","Validation loss per 100 evaluation steps: 0.017934394023741047\n","Validation loss per 100 evaluation steps: 0.01836636372914636\n","Validation loss per 100 evaluation steps: 0.01809839386242371\n","Validation loss per 100 evaluation steps: 0.018217984880332938\n","Validation loss per 100 evaluation steps: 0.01823543408164426\n","Validation loss per 100 evaluation steps: 0.01867774473252663\n","Validation loss per 100 evaluation steps: 0.018841724091881118\n","Validation loss per 100 evaluation steps: 0.0189141025872468\n","Validation loss per 100 evaluation steps: 0.018900859907815412\n","Validation loss per 100 evaluation steps: 0.01891749583096808\n","Validation loss per 100 evaluation steps: 0.018896628184020787\n","Validation loss per 100 evaluation steps: 0.01870127094927389\n","Validation loss per 100 evaluation steps: 0.018954583806626492\n","Validation loss per 100 evaluation steps: 0.018942970022997135\n","Validation loss per 100 evaluation steps: 0.018896598838478492\n","Validation loss per 100 evaluation steps: 0.018840068358276757\n","Validation loss per 100 evaluation steps: 0.018784723077535526\n","Validation loss per 100 evaluation steps: 0.018693513716480363\n","Validation loss per 100 evaluation steps: 0.0187676611024856\n","Validation loss per 100 evaluation steps: 0.018691054398727203\n","Validation loss per 100 evaluation steps: 0.018780527097325268\n","Validation loss per 100 evaluation steps: 0.018863461324406448\n","Validation loss per 100 evaluation steps: 0.018964766829574924\n","Validation loss per 100 evaluation steps: 0.019310834691028855\n","Validation loss per 100 evaluation steps: 0.01941348241187268\n","Validation loss per 100 evaluation steps: 0.019499364818066252\n","Validation loss per 100 evaluation steps: 0.019388721766505173\n","Validation loss per 100 evaluation steps: 0.019485547258097098\n","Validation loss per 100 evaluation steps: 0.01947426821877344\n","Validation loss per 100 evaluation steps: 0.019456613335615845\n","Validation loss per 100 evaluation steps: 0.019459447810053203\n","Validation loss per 100 evaluation steps: 0.01940127071349154\n","Validation loss per 100 evaluation steps: 0.01945500529688024\n","Validation loss per 100 evaluation steps: 0.01946440723045506\n","Validation loss per 100 evaluation steps: 0.01947476137964501\n","Validation loss per 100 evaluation steps: 0.0193873546747271\n","Validation loss per 100 evaluation steps: 0.019337099986050578\n","Validation loss per 100 evaluation steps: 0.019423413531131497\n","Validation loss per 100 evaluation steps: 0.019405400092793637\n","Validation loss per 100 evaluation steps: 0.01935669878857694\n","Validation loss per 100 evaluation steps: 0.01937327634758899\n","Validation loss per 100 evaluation steps: 0.019354199292932344\n","Validation loss per 100 evaluation steps: 0.01934640421053939\n","Validation loss per 100 evaluation steps: 0.019325595997225782\n","Validation loss per 100 evaluation steps: 0.019329591009552158\n","Validation loss per 100 evaluation steps: 0.019345667612384536\n","Validation loss per 100 evaluation steps: 0.0194694026320247\n","Validation loss per 100 evaluation steps: 0.01944249122254201\n","Validation loss per 100 evaluation steps: 0.019441287918130594\n","Validation loss per 100 evaluation steps: 0.019379362758834593\n","Validation loss per 100 evaluation steps: 0.019425427288672116\n","Validation loss per 100 evaluation steps: 0.019421443113981786\n","Validation loss per 100 evaluation steps: 0.019362696063287797\n","Validation loss per 100 evaluation steps: 0.01936990561322414\n","Validation loss per 100 evaluation steps: 0.019409002027951625\n","Validation loss per 100 evaluation steps: 0.019419459422391688\n","Validation loss per 100 evaluation steps: 0.019438857104487534\n","Validation loss per 100 evaluation steps: 0.019429740068420374\n","Validation loss per 100 evaluation steps: 0.019454986982335616\n","Validation loss per 100 evaluation steps: 0.019471521562665954\n","Validation loss per 100 evaluation steps: 0.0195054587397771\n","Validation loss per 100 evaluation steps: 0.019482183167862904\n","Validation loss per 100 evaluation steps: 0.01947240265564442\n","Validation loss per 100 evaluation steps: 0.019448650505347075\n","Validation loss per 100 evaluation steps: 0.01939512162063616\n","Validation loss per 100 evaluation steps: 0.01939786579940517\n","Validation loss per 100 evaluation steps: 0.019419880873119834\n","Validation loss per 100 evaluation steps: 0.01940221607318623\n","Validation loss per 100 evaluation steps: 0.01945456468830621\n","Validation loss per 100 evaluation steps: 0.019438045560092876\n","Validation loss per 100 evaluation steps: 0.019425005827231487\n","Validation loss per 100 evaluation steps: 0.019396358113620893\n","Validation loss per 100 evaluation steps: 0.019400553294524014\n","Validation loss per 100 evaluation steps: 0.0193944746369341\n","Validation loss per 100 evaluation steps: 0.01939711164607648\n","Validation loss per 100 evaluation steps: 0.01944818358188198\n","Validation loss per 100 evaluation steps: 0.019418836944458923\n","Validation loss per 100 evaluation steps: 0.019387827871284073\n","Validation loss per 100 evaluation steps: 0.01937330384979842\n","Validation loss per 100 evaluation steps: 0.019310091895588556\n","Validation loss per 100 evaluation steps: 0.019306968882307526\n","Validation loss per 100 evaluation steps: 0.01932148170755151\n","Validation loss per 100 evaluation steps: 0.019357318421025567\n","Validation loss per 100 evaluation steps: 0.019356212102911857\n","Validation loss per 100 evaluation steps: 0.019339421523543395\n","Validation loss per 100 evaluation steps: 0.019313071391956295\n","Validation loss per 100 evaluation steps: 0.019282931324485\n","Validation loss per 100 evaluation steps: 0.01927073413683761\n","Validation loss per 100 evaluation steps: 0.019264640325958843\n","Validation loss per 100 evaluation steps: 0.01922571632007795\n","Validation loss per 100 evaluation steps: 0.019276037796633276\n","Validation loss per 100 evaluation steps: 0.01924085280008939\n","Validation Loss: 0.019262908629077903\n","Validation Accuracy: 0.9489014561002307\n"]}]},{"cell_type":"markdown","source":["# Evaluation Metrics"],"metadata":{"id":"mi41icZw11MF"}},{"cell_type":"code","source":["from seqeval.metrics import classification_report\n","\n","print(classification_report([labels], [predictions]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7L1uBQfYI-gm","executionInfo":{"status":"ok","timestamp":1686667081134,"user_tz":-330,"elapsed":4259,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"210d5316-5dd9-4aa3-e341-8be852be2404"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       BRAND       0.79      0.77      0.78     33388\n","\n","   micro avg       0.79      0.77      0.78     33388\n","   macro avg       0.79      0.77      0.78     33388\n","weighted avg       0.79      0.77      0.78     33388\n","\n"]}]},{"cell_type":"code","source":["import os\n","\n","directory = \"/content/drive/MyDrive/Colab Notebooks/Product_Feature_ner/model\"\n","\n","if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","# save vocabulary of the tokenizer\n","tokenizer.save_vocabulary(directory)\n","# save the model weights and its configuration file\n","model.save_pretrained(directory)\n","print('All files saved')\n","print('This tutorial is completed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjmzQLtcI__7","executionInfo":{"status":"ok","timestamp":1686667236195,"user_tz":-330,"elapsed":2400,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"c075477b-b487-428c-a94c-66e19b21c2e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All files saved\n","This tutorial is completed\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","pipe = pipeline(task=\"token-classification\", model=model.to(\"cpu\"), tokenizer=tokenizer, aggregation_strategy=\"simple\")\n","pipe(\"Fly Me to Leanin ' Tree the Moon - Josephine Wall Birthday Card\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-YcVHn4MivB","executionInfo":{"status":"ok","timestamp":1686667313178,"user_tz":-330,"elapsed":6537,"user":{"displayName":"Purchase - Techversant Infotech","userId":"04917963250138759673"}},"outputId":"22e32e30-6d21-405d-a31f-d5b7916487e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'entity_group': 'BRAND',\n","  'score': 0.502654,\n","  'word': \"' tree\",\n","  'start': None,\n","  'end': None}]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"PcwJcYKPNKJA"},"execution_count":null,"outputs":[]}]}